In order to virtualize the CPU, the OS **time sharing** the CPU: run one process for a little while, then run another one, and so forth.

The two challenges of time sharing:

1. **Performance**
1. **Control** (How does the OS retain control of the machine?)

- [Mechanism: Limited Direct Execution](#mechanism-limited-direct-execution)
  - [Problem #1: Restricted Operations](#problem-1-restricted-operations)
    - [Two Processor Modes](#two-processor-modes)
    - [System Call](#system-call)
  - [Problem #2: Switching Between Processes](#problem-2-switching-between-processes)
    - [A cooperative Approach: Wait For System Calls](#a-cooperative-approach-wait-for-system-calls)
    - [A Non-Cooperative Approach: The OS Takes Control](#a-non-cooperative-approach-the-os-takes-control)
    - [Saving and Restoring Context (Context Switch)](#saving-and-restoring-context-context-switch)
- [Scheduling Policies](#scheduling-policies)
  - [Turnaround Time](#turnaround-time)
  - [Response Time](#response-time)
  - [Incorporating I/O](#incorporating-io)
  - [Multi-Level Feedback Queue](#multi-level-feedback-queue)
  - [Proportional Share](#proportional-share)
    - [Lottery Scheduling](#lottery-scheduling)
    - [Stride Scheduling](#stride-scheduling)
    - [The Linux Completely Fair Scheduler (CFS)](#the-linux-completely-fair-scheduler-cfs)

The mechanism for virtualization of the CPU is **Limited Direct Execution**.

# Mechanism: Limited Direct Execution

**Direct Execution** is simple: just un the program directly on the CPU. However, this introduces two problems:

1. If we just run a program, how can the OS make sure the program doesn't do anything that we don't want it to do, while still running it efficiently?
1. When we are running a process, how does the OS stop it from running and switch to another process, thus implementing the **time sharing** we require to virtualize the CPU?

## Problem #1: Restricted Operations

> The CRUX:
>
> A process must be able to perform I/O and some other restricted operations, but without giving the process complete control over the system. How can the OS and hardware work together to do so?

The solution consists of having two processor modes(**user mode** and **kernel mode**) and exposing **system calls**.

### Two Processor Modes

**User Mode**: Code that runs in user mode is restricted in what it can do.

**Kernel Mode**: Which the OS (or kernel) runs in. In this mode, code that runs can do what it likes, including privileged operations such as issuing I/O requests and executing all types of restricted instructions.

### System Call

To execute a system call, a program must execute a special **trap** instruction. The instruction simultaneously jumps into the kernel and raises the privilege level to kernel mode; once in the kernel, the system can not perform whatever privileged operations are needed(if allowed), and thus do the required work for the calling process. When finished, the OS calls a special **return-from-trap** instruction, which, as you might expect, returns into the calling user program while simultaneously reducing the privilege level back to user mode.

The hardware needs to be a bit careful when executing a trap, in that it must make sure to save enough of the caller's registers in order to be able to return correctly when the OS issues the return-from-trap instruction. On x86, the processor will push the program counter, flags, and a few other registers on a per-process **kernel stack**; the return-from-trap will pop these values off the stack and resume execution of the user-mode program.

_There is one important detail left out of this discussion: how does the trap know which doe to run inside the OS?_

The kernel does so by setting up a **trap table** at boot time. When the machine boots up, it does so in privileged(kernel) mode, and thus is free to configure machine hardware as need be. One of the first things the OS thus does it to tell the hardware what code to run when certain execeptional event occur. The OS informs the hardware of the locations of these **trap handlers**, usually with some kind of special instruction. Once the hardware is informed, it remembers the location of these handlers until the machine is next rebooted, and thus the hardware knows what to do (i.e., what code to jump to) when system calls and other exceptional events take place.

To specify the exact system call, a **system-call number** is usually assigned to each system call. Ths user code thus responsible for placing the desired system-call number in a register or at a specified location on the stack; ths OS, when handling the system call inside the trap handler, examines this number, ensures it is valid, and, if it is, executes the corresponding code. This level of indirection serves as a form of **protection**; user code cannot specify an exact address to jump to, but rather must request a particular service via number.

One last aside: being able to execute the instruction to tell the hardware where the trap tables are is a very powerful capability. Thus, as you might have guesses, it is also a **privileged** operation.

## Problem #2: Switching Between Processes

If a process is running on the CPU, this by definition means the OS is _not_ running. If the OS is not running, how can it do anything at all?

> The CRUX:
>
> How can the OS **regain control** of the CPU so that it can switch between processes.

### A cooperative Approach: Wait For System Calls

In this style, the OS _trusts_ the processes of the system to behave reasonably. Processes that run for too long are assumed to periodically give up the CPU so that the OS can decide to run some other task.

How does a friendly process give up the CPU in this utopian world? Most processes, as it turns out, transfer control of the CPU to the OS quite frequently by making **system calls**, for example, to open a file and subsequently read it, or to send a message to another machine, or to create a new process. Systems using this cooperative approach often include an explicit **yield** system call, which does nothing except to transfer control to the OS so it can run other processes.

Applications also transfer control to the OS when they do something illegal.

Thus, in a cooperative scheduling system, the OS regains control of the CPU by waiting for a system call or an illegal operation of some kind to take place.

### A Non-Cooperative Approach: The OS Takes Control

Without some additional help from the hardware, it turns out the OS can't do much at all when a process refuses to make system calls (or mistakes) and thus return control to the OS. In fact, in the cooperative approach, your only resource when a process gets stuck in an infinite loop is to resort to the age-old solution to all problems in computer systems: **reboot the machine**.

> The CRUX:
>
> How can the OS gain control of the CPU even if processes are not being cooperative? What can the OS do to ensure a rogue process does not take over the machine?

The solution is a **timer interrupt**.

A timer device can be programmed to raise an interrupt every so many milliseconds; when the interrupt is raised, the currently running process is halted, and a pre-configured **interrupt handler** in the OS runs. At this point, the OS has regained control of the CPU, and thus can do what it pleases: stop the current process, and start a different one.

As we discussed before with system calls, the OS must inform the hardware of which code to run when the timer interrupt occurs; thus, at boot time, the OS does exactly that. Second, also during the boot sequence, the OS must start the timer, which is of course a privileged operation. Once the timer has begun, the OS can thus fell safe in that control will eventually be returned to it, and thus the OS is free to run user programs. THe timer can also be turned off(also a privileged operation).

Note that the hardware has some responsibility when an interrupt occurs, in particular to save enough of the state of the program that was running when the interrupt occurred such that a subsequent return-from-trap instruction will be able to resume the running program correctly.

### Saving and Restoring Context (Context Switch)

Now that the OS has regained control. whether cooperatively via a system call, or more forcefully via a timer interrupt, a decision has to be made: whether to continue running the currently-running process, or switch to a different one. This decision is made by a part of the operating system known as the **scheduler**.

If the decision is made to switch, the OS them executes a low-level piece of code which we refer to as a **context switch**. A context switch is conceptually simple: all the OS has to do is save a few register values for the currently-executing process (onto its kernel stack, for example) and restore a few for the soon-to-be-executing process (from its kernel stack). By doing so, the OS thus ensures that when the return-from-trap instruction is finally executed, instead of returning to the process that was running, the system resumes execution of another process.

If the OS decides to switch from running process A to process B. At that point, it calls the `switch()` routine, which carefully saves current register values (into the process structure of A), restores the registers of process B (from its process structure entry), and then **switches contexts**, specifically by changing the stack pointer to use B's kernel stack (and not A's). Finally, the OS returns-from-trap, which restores B's registers and starts running it.

Note that there are two types of register saves/restores that happen during this protocol. The first is when the timer interrupt occurs; in this case, the _user registers_ of the running process are implicitly saved by the _hardware_, using the kernel stack of that process. The second is when the OS decides to switch from A to B; in this case, the _kernel registers_ are explicitly saved by the _software_ (i.e., the OS), but this time into memory in the process structure of the process. The latter action moves the system from running as if it just trapped into the kernel from A to as if it just trapped in the kernel from B.

# Scheduling Policies

Two Scheduling Policies Metrics: **turnaround time** and **response time**.

T<sub>turnaround</sub> = T<sub>completion</sub> - T<sub>arrival</sub>

T<sub>response</sub> = T<sub>firstrun</sub> - T<sub>arrival</sub>

## Turnaround Time

The optimal policy for turnaround time is **Shortest Time-to-Completion First(STCF)**.

Any time a new job enters the system, the STCF scheduler determines which of the remaining jobs (including the new job) has the least time left, and schedules that one.

## Response Time

The policy that optimizes response time is **Round-Robin(RR)**.

Instead of running jobs to completion, RR runs a job for a **time slice** (sometimes called a **scheduling quantum**) and then switches to the next job in the run queue. It repeatedly does so until the jobs are finished. For this reason, RR is sometimes called **time-slicing**.

## Incorporating I/O

A scheduler clearly has a decision to make when a job initiates an I/O request, because the currently-running job won't be using the CPU during the I/O; it is **blocked** waiting for I/O completion. Thus, the scheduler should probably schedule another job on the CPU at that time.

By treating each CPU burst as a job, the scheduler makes sure processes that are "interactive" get run frequently. While those interactive jobs are performing I/O, other CPU-intensive jobs run, thus better utilizing the processor.

> How can we build an approach that behaves like STCF without such _a priori_ knowledge? Further, how can we incorporate some of the ideas we have seen with the RR scheduler so that response time is also quite good?

## Multi-Level Feedback Queue

One of the most well-known approaches to scheduling, known as the **Multi-level Feedback Queue(MLFQ)**. First, it would like to optimize _turnaround time_. Second, MLFQ would like to make a system fell responsive to interactive users.

The MLFQ has a number of distinct **queues**, each assigned a different **priority level**. At any given time, a job that is ready to run is on a single queue. MLFQ uses priorities to decide which job should run at a given time: a job with higher priority (i.e., a job on a higher queue) is chosen to run.

Of course, more than one job may be on a given queue, and thus have the _same_ priority. In this case, we wil just use round-robin scheduling among those jobs.

MLFQ has _multiple levels_ of queues, and uses _feedback_ to determine the priority of a given job.

Here are the rules:

1. If Priority(A) > Priority(B), A runs (B doesn't)
1. If Priority(A) = Priority(B), A & B run in RR.
1. When a job enters the system, it is placed at the highest priority(the topmost queue).
1. Once a job uses up its time allotment at a given level (regardless of how many times it has given up the CPU), its priority is reduced (i.e., it moves down one queue).
1. After some time period _S_, move all the jobs in the system to the topmost queue.

## Proportional Share

There is a different type of scheduler known as a **proportional-share** scheduler, also sometimes referred to as a **fair-share** scheduler. Instead of optimizing for turnaround or response time, a scheduler might instead try to guarantee that each job obtain a certain percentage of CPU time.

### Lottery Scheduling

Basic idea is quite simple: every so often, hold a lottery to determine which process should get to run next; processes that should run more often should be given more chances to win the lottery.

Underlying lottery scheduling is one very basic concept: **tickets**, which are used to represent the share of a resource that a process (or user or whatever) should receive. The percent of tickets that a process has represents its share of the system resource in question.

Lottery scheduling achieves this probabilistically (but not deterministically) by holding a lottery every so often. Holding a lottery is straightforward: the scheduler must know how many total tickets there are. The scheduler then picks a winning ticket. The processor then loads the state of that winning process and runs it.

The use of randomness in lottery scheduling leads to a probabilistic correctness in meeting the desired proportion, but no guarantee. However, the longer these jobs compete, the more likely they are to achieve the desired percentages.

### Stride Scheduling

**Stride Scheduling** is a deterministic fair-share scheduler.

Each job in the system has a stride, which is inverse in proportion to the number of tickets it has. For example, with jobs A, B and C, with 100, 50, and 250 tickets, respectively, we can compute the stride of each by dividing some large number by the number of tickets each process has be assigned. For example, if we divide 10,000 by each of those ticket values, we obtain the following stride values for A, B, and C: 100, 200, and 40. We call this value the **stride** of each process; every time a process runs, we will increment a counter for it (called its **pass** value) by its stride to track its global progress.

At any given time, pick the process to run that has the lowest pass value so far; when you run a process, increment its pass counter by its stride.

Lottery scheduling achieves the proportions probabilistically over time; stride scheduling gets them exactly right at the end of each scheduling cycle.

Lottery scheduling has one nice property that stride scheduling does not: no global state. Imagine a new job enters in the middle of our stride scheduling example above; what should its pass value be? Should it be set to 0? Is fo, it will monopolize the CPU. With lottery scheduling, there is no global state per process; we simply add a new process with whatever tickets it has, update the single global variable to track how many total tickets we have, and go from there. In this way, lottery makes it much easier to incorporate new processes in a sensible manner.

### The Linux Completely Fair Scheduler (CFS)
